{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7i4dt5Dc42Js",
    "outputId": "2041c790-92e6-4169-9ae5-b61446ffb2bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2ITOCwq-e_-"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import GradCAM, LayerCAM\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import deprocess_image, \\\n",
    "    preprocess_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img: np.ndarray,\n",
    "                      mask: np.ndarray,\n",
    "                      use_rgb: bool = False,\n",
    "                      colormap: int = cv2.COLORMAP_JET) -> np.ndarray:\n",
    "    \"\"\" This function overlays the cam mask on the image as an heatmap.\n",
    "    By default the heatmap is in BGR format.\n",
    "    :param img: The base image in RGB or BGR format.\n",
    "    :param mask: The cam mask.\n",
    "    :param use_rgb: Whether to use an RGB or BGR heatmap, this should be set to True if 'img' is in RGB format.\n",
    "    :param colormap: The OpenCV colormap to be used.\n",
    "    :returns: The default image with the cam overlay.\n",
    "    \"\"\"\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
    "    if use_rgb:\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    x = heatmap\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "    if np.max(img) > 1:\n",
    "        raise Exception(\n",
    "            \"The input image should np.float32 in the range [0, 1]\")\n",
    "\n",
    "    cam = heatmap + img\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'C:/Users/tcemcetin/Documents/Y端ksekLisans/TrustableAIProject/'\n",
    "df = pd.read_csv(root_path + 'dataset/stage_2_train_labels.csv')\n",
    "df = df[df.Target == 1]\n",
    "df['area'] = df.apply(lambda r: r.height * r.width, axis=1)\n",
    "df = df.sort_values(['patientId', 'area'], ascending=False).drop_duplicates('patientId', keep='first')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    \"\"\"\n",
    "      Choose the target layer you want to compute the visualization for.\n",
    "      Usually this will be the last convolutional layer in the model.\n",
    "      Some common choices can be:\n",
    "      Resnet18 and 50: model.layer4[-1]\n",
    "      VGG, densenet161: model.features[-1]\n",
    "      mnasnet1_0: model.layers[-1]\n",
    "      You can print the model to help chose the layer\n",
    "      You can pass a list with several target layers,\n",
    "      in that case the CAMs will be computed per layer and then aggregated.\n",
    "      You can also try selecting all layers of a certain type, with e.g:\n",
    "      from pytorch_grad_cam.utils.find_layers import find_layer_types_recursive\n",
    "      find_layer_types_recursive(model, [torch.nn.ReLU])\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if model_name == \"resnet_50_raw\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        target_layers = [model.layer4[-1]]\n",
    "    \n",
    "    elif model_name == \"densenet161_raw\":\n",
    "        model = models.densenet161(pretrained=True)\n",
    "        target_layers = [model.features[-1]]\n",
    "\n",
    "    elif model_name == \"resnet_special\":\n",
    "        model = torch.load('./models/resnet_fold1/checkpoint_38.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.layer4[-1]]\n",
    "        \n",
    "    elif model_name == \"densenet_special\":\n",
    "        model = torch.load('./models/densenet_fold1/checkpoint_31.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.features[-1]]\n",
    "    \n",
    "    elif model_name == \"resnet_special_v2\":\n",
    "        model = torch.load('./models/resnet_fold0/checkpoint_10.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.layer4[-1]]\n",
    "        \n",
    "    elif model_name == \"densenet_special_v2\":\n",
    "        model = torch.load('./models/densenet_fold0/checkpoint_10.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.features[-1]]\n",
    "        \n",
    "    elif model_name == \"densenet_special_v3\":\n",
    "        model = torch.load('./models/densenet_fold3/checkpoint_6.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.features[-1]]\n",
    "    \n",
    "    elif model_name == \"resnet_special_v3\":\n",
    "        model = torch.load('./models/densenet_fold2/checkpoint_7.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.layer4[-1]]\n",
    "        \n",
    "    elif model_name == \"densenet_model_fold0\":\n",
    "        model = torch.load(f'./models/models/DenseNet/dense_fold0/checkpoint_10.pth.tar', map_location=torch.device('cpu'))['model']\n",
    "        target_layers = [model.features[-1]]\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "    return model, target_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpPDqQE-4sYV"
   },
   "outputs": [],
   "source": [
    "def load_img(image_path):\n",
    "    dcm_file = pydicom.read_file(image_path)\n",
    "    img_arr = dcm_file.pixel_array\n",
    "    img = Image.fromarray(img_arr).convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess(img):\n",
    "    img_raw = img.copy()\n",
    "    if img_raw.size[0] > img_raw.size[1]:\n",
    "        img_raw.thumbnail((1000000, 256))\n",
    "    else:\n",
    "        img_raw.thumbnail((256 ,1000000))\n",
    "    \n",
    "    Left = (img_raw.width - 224) / 2\n",
    "    Right = Left + 224\n",
    "    Top = (img_raw.height - 244) / 2\n",
    "    Buttom = Top + 224\n",
    "    img_raw = img_raw.crop((Left, Top, Right, Buttom))\n",
    "    \n",
    "    return img_raw\n",
    "\n",
    "def create_mask(row):\n",
    "    mask = np.zeros((1024,1024), dtype=int)\n",
    "    y = int(row['y'])\n",
    "    y_max = int(row['y']+row['height']+1)\n",
    "    x =  int(row['x'])\n",
    "    x_max = int(row['x']+row['width']+1)\n",
    "    mask[y:y_max+1, x:x_max] = 1\n",
    "    return mask, (y, x), (y_max, x_max)\n",
    "        \n",
    "\n",
    "def calculate_IOU(mask, heatmap):\n",
    "    overlap = mask*heatmap # Logical AND\n",
    "    union = mask + heatmap # Logical OR\n",
    "    IOU = overlap.sum()/float(union.sum())\n",
    "    return IOU\n",
    "\n",
    "def calculate_dice_score(mask, heatmap, k=1):\n",
    "    return np.sum(heatmap[mask==k])*2.0 / (np.sum(heatmap) + np.sum(mask))\n",
    "\n",
    "    \n",
    "def gcam(config, model, target_layers):\n",
    "    methods = \\\n",
    "        {\"gradcam\": GradCAM,\n",
    "          \"scorecam\": ScoreCAM,\n",
    "          \"gradcam++\": GradCAMPlusPlus,\n",
    "          \"ablationcam\": AblationCAM,\n",
    "          \"xgradcam\": XGradCAM,\n",
    "          \"eigencam\": EigenCAM,\n",
    "          \"eigengradcam\": EigenGradCAM,\n",
    "          \"layercam\": LayerCAM,\n",
    "          \"fullgrad\": FullGrad}\n",
    "\n",
    "    # rgb_img = cv2.imread(args.image_path, 1)[:, :, ::-1]\n",
    "    # rgb_img = np.float32(rgb_img) / 255\n",
    "    # input_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    img = load_img(config['root_path'] + config['img'] + \".dcm\")\n",
    "    rgb_img = preprocess(img)\n",
    "    rgb_img = np.float32(rgb_img) / 255\n",
    "    \n",
    "    \n",
    "    input_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # If None, returns the map for the highest scoring category.\n",
    "    # Otherwise, targets the requested category.\n",
    "    target_category = None\n",
    "\n",
    "    # Using the with statement ensures the context is freed, and you can\n",
    "    # recreate different CAM objects in a loop.\n",
    "    cam_algorithm = methods[config['method']]\n",
    "    with cam_algorithm(model=model,\n",
    "                        target_layers=target_layers,\n",
    "                        use_cuda=config['use_cuda']) as cam:\n",
    "\n",
    "        # AblationCAM and ScoreCAM have batched implementations.\n",
    "        # You can override the internal batch size for faster computation.\n",
    "        cam.batch_size = 32\n",
    "\n",
    "        grayscale_cam = cam(input_tensor=input_tensor,\n",
    "                            target_category=target_category,\n",
    "                            aug_smooth=config['aug_smooth'],\n",
    "                            eigen_smooth=config['eigen_smooth'])\n",
    "        \n",
    "        # Here grayscale_cam has only one image in the batch\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "        \n",
    "        cam_image,heatmap = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "        # cam_image is RGB encoded whereas \"cv2.imwrite\" requires BGR encoding.\n",
    "        cam_image = cv2.cvtColor(cam_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, use_cuda=config['use_cuda'])\n",
    "    gb = gb_model(input_tensor, target_category=target_category)\n",
    "\n",
    "    cam_mask = cv2.merge([grayscale_cam, grayscale_cam, grayscale_cam])\n",
    "    cam_gb = deprocess_image(cam_mask * gb)\n",
    "    gb = deprocess_image(gb)\n",
    "\n",
    "    return cam_image, gb, cam_gb, heatmap, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "KQpev9QM71Iy",
    "outputId": "ff99ad99-f29b-4677-96b9-c717a8f70929",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"root_path\": \"C:/Users/tcemcetin/Documents/Y端ksekLisans/TrustableAIProject/dataset/stage_2_train_images/\",\n",
    "    \"img\": \"00b4ac1b-fa09-4dbe-b93f-7d9e52992a68\",\n",
    "    \"aug_smooth\": True,\n",
    "    \"eigen_smooth\": False,\n",
    "    \"method\": \"xgradcam\",\n",
    "    \"use_cuda\": False\n",
    "}\n",
    "\n",
    "model_name = \"densenet_special\"\n",
    "model, target_layers = get_model(model_name)\n",
    "print(\"Model Loaded\")\n",
    "\n",
    "cam_image, gb, cam_gb, heatmap, img = gcam(config, model, target_layers)\n",
    "# plt.imshow(cam_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [\"densenet_special_v2\", \"resnet_special_v2\"]\n",
    "config = {\n",
    "    \"root_path\": \"C:/Users/tcemcetin/Documents/Y端ksekLisans/TrustableAIProject/dataset/stage_2_train_images/\",\n",
    "    \"img\": \"00b4ac1b-fa09-4dbe-b93f-7d9e52992a68\",\n",
    "    \"aug_smooth\": True,\n",
    "    \"eigen_smooth\": False,\n",
    "    \"method\": \"gradcam\",\n",
    "    \"use_cuda\": False,\n",
    "    \"th\": 150\n",
    "}\n",
    "liste = []\n",
    "cnt = 0\n",
    "for model_name in models[:1]:\n",
    "    model, target_layers = get_model(model_name)\n",
    "    print(\"Model Loaded\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        print(row['patientId'])\n",
    "        config['img'] = row['patientId']\n",
    "        mask, start_point, end_point = create_mask(row)\n",
    "        cam_image, gb, cam_gb, heatmap, img = gcam(config, model, target_layers)\n",
    "        \n",
    "        # Heatmap oversize\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_RGB2GRAY)\n",
    "        heatmap = cv2.resize(heatmap, (1024,1024), interpolation=cv2.INTER_AREA)\n",
    "        # heatmap = (heatmap > 180).astype(int)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        rectangle = cv2.rectangle(cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR), start_point, end_point, (255, 0, 0), 2)\n",
    "        plt.imshow(rectangle)\n",
    "        plt.show()\n",
    "        \n",
    "        IOU = calculate_IOU(mask, heatmap)\n",
    "        liste.append(IOU)\n",
    "        plt.imshow(cam_image)\n",
    "        plt.show()\n",
    "        cnt += 1\n",
    "        if cnt > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [\"densenet_special_v2\", \"resnet_special_v2\"]\n",
    "config = {\n",
    "    \"root_path\": \"C:/Users/tcemcetin/Documents/Y端ksekLisans/TrustableAIProject/dataset/rsna-pneumonia-detection-challenge/stage_2_train_images/\",\n",
    "    \"img\": \"00b4ac1b-fa09-4dbe-b93f-7d9e52992a68\",\n",
    "    \"aug_smooth\": True,\n",
    "    \"eigen_smooth\": False,\n",
    "    \"method\": \"layercam\",\n",
    "    \"use_cuda\": False,\n",
    "    \"th\": 150\n",
    "}\n",
    "liste2 = []\n",
    "cnt = 0\n",
    "for model_name in models[:1]:\n",
    "    model, target_layers = get_model(model_name)\n",
    "    print(\"Model Loaded\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        print(row['patientId'])\n",
    "        config['img'] = row['patientId']\n",
    "        mask, start_point, end_point = create_mask(row)\n",
    "        cam_image, gb, cam_gb, heatmap, img = gcam(config, model, target_layers)\n",
    "\n",
    "        # Heatmap oversize\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_RGB2GRAY)\n",
    "        heatmap = cv2.resize(heatmap, (1024,1024), interpolation=cv2.INTER_AREA)\n",
    "        heatmap_th = (heatmap > 180).astype(int)\n",
    "\n",
    "        # Draw rectangle\n",
    "        rectangle = cv2.rectangle(cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR), start_point, end_point, (255, 0, 0), 2)\n",
    "        plt.imshow(rectangle)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(heatmap)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(heatmap_th)\n",
    "        plt.show()\n",
    "\n",
    "        IOU = calculate_IOU(mask, heatmap)\n",
    "        IOU = calculate_IOU(mask, heatmap_th)\n",
    "        liste2.append(IOU)\n",
    "        plt.imshow(cam_image)\n",
    "        plt.show()\n",
    "        cnt += 1\n",
    "        if cnt > 200:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask the image and create the new histogram\n",
    "histogram, bin_edges = np.histogram(heatmap, bins=100, range=(0.0, 255))\n",
    "\n",
    "# configure and draw the histogram figure\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([0.0, 255])\n",
    "plt.plot(bin_edges[25:-1], histogram[25:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "mean(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "mean(liste2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import transforms,models\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from train import train_function, save_checkpoint\n",
    "from test import test_function\n",
    "from pneumonia import Pneumonia\n",
    "import pandas as pd\n",
    "from train import calculateMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {'Normal': 0, 'Lung Opacity': 1}\n",
    "cat_to_name = {class_to_idx[i]: i for i in list(class_to_idx.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                        transforms.Resize((224, 224)),\n",
    "                        transforms.CenterCrop(224),\n",
    "                        transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "                        transforms.RandomRotation(10),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                    ]),\n",
    "    \n",
    "            'test': transforms.Compose([\n",
    "                        transforms.Resize((224,224)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                        ]),\n",
    "    \n",
    "            'valid': transforms.Compose([\n",
    "                        transforms.Resize((224,224)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                    ])\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu') \n",
    "batch_size = 1\n",
    "train_on_gpu = True\n",
    "model, _ = get_model('densenet_special_v3')\n",
    "\n",
    "\n",
    "valid_data = Pneumonia('X_test_fold_0.txt', class_to_idx=class_to_idx, transforms=data_transforms['train'])\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "number_correct, number_data = 0, 0\n",
    "for data, target in tqdm(valid_loader):\n",
    "    if train_on_gpu:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "    output = torch.squeeze(model(data))\n",
    "    pred = output\n",
    "    print(pred)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os, json\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = Pneumonia('X_test_fold_0.txt', class_to_idx=class_to_idx)\n",
    "img, label = valid_data.__getitem__(5)\n",
    "model, _ = get_model('densenet_special_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pil_transform(): \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((224, 224))\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_preprocess_transform():\n",
    "    transf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])    \n",
    "\n",
    "    return transf    \n",
    "\n",
    "pill_transf = get_pil_transform()\n",
    "preprocess_transform = get_preprocess_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(images):\n",
    "    model.eval()\n",
    "    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    logits = model(batch)\n",
    "    result = []\n",
    "    \n",
    "    for l in logits.detach().cpu().numpy():\n",
    "        if l >= 0.5:\n",
    "            result.append((1-l, l))\n",
    "        else:\n",
    "            result.append((l, 1-l))\n",
    "    result = np.array(result)\n",
    "    # probs = F.softmax(logits, dim=1)\n",
    "    #return probs.detach().cpu().numpy()\n",
    "    return np.squeeze(result, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = batch_predict([pill_transf(img)])\n",
    "test_pred.squeeze().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(pill_transf(img)), \n",
    "                                         batch_predict, # classification function\n",
    "                                         top_labels=2, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
    "img_boundry2 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    tmp, _ = np.histogram(img, bins=50, range=(0.0, 255))\n",
    "    histogram += tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram, bin_edges = np.histogram(img, bins=20, range=(0.0, 255))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([0.0, 255])\n",
    "plt.plot(bin_edges[0:-1], histogram)\n",
    "plt.savefig('foo.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  -------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gcam",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
